{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869fb837-0d1f-4790-9318-8aff52b75ef9",
   "metadata": {},
   "source": [
    "## Convective/Stratiform identification for 3D Reflectivity from derived dBZ of WRF Simulations. \n",
    "\n",
    "**For [High Resolution WRF Simulations of the Current and Future Climate of North America](https://rda.ucar.edu/datasets/ds612.0/).**\n",
    "\n",
    "**Hungjui Yu 20210927**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70de2b4e-ad2a-429f-ad4d-c27561e36fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import sys\n",
    "from shutil import copyfile\n",
    "import time\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from netCDF4 import (Dataset, MFDataset)\n",
    "import numpy as np\n",
    "from scipy.interpolate import interpn\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import wrf\n",
    "from wrf import (getvar, vinterp, interplevel, extract_times, destagger)\n",
    "\n",
    "# import metpy\n",
    "# import metpy.calc as mpcalc\n",
    "# import metpy.units as units\n",
    "# print(metpy.__version__)\n",
    "# import dask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc002f5-0b9b-4623-9125-4bbc79e62cb1",
   "metadata": {},
   "source": [
    "**Set input files paths and names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f06ea2c-4b38-4bdc-9459-a47621e73e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dbz': '/glade/scratch/hungjui/DATA_WRF_CONUS_1_dBZ_v1.0/CTRL3D/2013/wrf3d_d01_CTRL_dbz_20130913.nc', 'Z': '/gpfs/fs1/collections/rda/data/ds612.0/CTRL3D/2013/wrf3d_d01_CTRL_Z_20130913.nc'}\n"
     ]
    }
   ],
   "source": [
    "def set_input_names(file_date):\n",
    "\n",
    "    file_path_1 = '/gpfs/fs1/collections/rda/data/ds612.0'\n",
    "    file_path_1_dbz = '/glade/scratch/hungjui/DATA_WRF_CONUS_1_dBZ_v1.0'\n",
    "    file_path_2 = '/' + wrf_sim_type # '/CTRL3D'\n",
    "    file_path_3 = '/{}'.format(file_date.strftime('%Y'))\n",
    "\n",
    "    file_names = dict( dbz = file_path_1_dbz\n",
    "                           + file_path_2 \n",
    "                           + file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_dbz_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                       , Z = file_path_1 \n",
    "                           + file_path_2 \n",
    "                           + file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_Z_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                     )\n",
    "    \n",
    "    return file_names\n",
    "\n",
    "wrf_sim_type = 'CTRL3D'\n",
    "file_name_list = set_input_names(dt.datetime(2013,9,13))\n",
    "print(file_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623103f-a594-43a8-a3b5-8a5f0eab50a6",
   "metadata": {},
   "source": [
    "**Test inserting Z into Netcdf4 dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6888da2-36e2-43fe-b2d4-accbffce13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncds_wrf_dbz = Dataset(file_name_list['dbz'], 'a') # , format=\"NETCDF4\")\n",
    "\n",
    "tmp_wrf_data = '/glade/scratch/hungjui/temp/tmp_wrf_dbz.nc'\n",
    "copyfile(file_name_list['dbz'], tmp_wrf_data)\n",
    "ncds_wrf_dbz = Dataset(tmp_wrf_data, 'a')\n",
    "\n",
    "ncds_wrf_z = Dataset(file_name_list['Z'])\n",
    "data_wrf_z_unstag = wrf.destagger(getvar(ncds_wrf_z, 'Z', timeidx=wrf.ALL_TIMES, meta=False), 1)\n",
    "ncds_wrf_z.close()\n",
    "\n",
    "GEO_H = ncds_wrf_dbz.createVariable('Z', 'f4', ('Time', 'bottom_top', 'south_north', 'west_east'))\n",
    "GEO_H[:] = data_wrf_z_unstag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "701448ca-1749-46c6-940a-522bf2ac4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncds_wrf_dbz.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5356d44-ab08-415d-945e-0e5003ef3828",
   "metadata": {},
   "source": [
    "**Test wrf.interplevel directly:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbe09693-a8f7-4c83-8a4e-b767c49c6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrf_dbz = getvar(ncds_wrf_dbz, 'dBZ', meta=False)\n",
    "\n",
    "ds_wrf_dbz = xr.open_dataset(file_name_list['dbz'])\n",
    "da_wrf_dbz = ds_wrf_dbz['dBZ'].isel(Time=0)\n",
    "\n",
    "data_wrf_z_unstag = wrf.destagger(getvar(Dataset(file_name_list['Z']), 'Z', timeidx=0, meta=False), 0)\n",
    "\n",
    "interp_vertical_lev = [2500] # meter inheight.\n",
    "\n",
    "dbz_lev = interplevel(da_wrf_dbz, data_wrf_z_unstag, interp_vertical_lev)\n",
    "\n",
    "# interp_field = vinterp(ncds_wrf_dbz,\n",
    "#                        field=wrf_dbz, # getvar(wrf_dbz, 'dBZ', meta=False),\n",
    "#                        vert_coord='ght_msl',\n",
    "#                        interp_levels=interp_levels,\n",
    "#                        extrapolate=False,\n",
    "#                        field_type='ght',\n",
    "#                        log_p=False,\n",
    "#                        timeidx=0,\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb7ef7c7-0175-40c1-be30-0bc2ca0da2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'dBZ_interp' (south_north: 1015, west_east: 1359)>\n",
      "array([[-30., -30., -30., ..., -30., -30., -30.],\n",
      "       [-30., -30., -30., ..., -30., -30., -30.],\n",
      "       [-30., -30., -30., ..., -30., -30., -30.],\n",
      "       ...,\n",
      "       [-30., -30., -30., ..., -30., -30., -30.],\n",
      "       [-30., -30., -30., ..., -30., -30., -30.],\n",
      "       [-30., -30., -30., ..., -30., -30., -30.]], dtype=float32)\n",
      "Coordinates:\n",
      "    Time     datetime64[ns] 2013-09-13\n",
      "    XLAT     (south_north, west_east) float32 ...\n",
      "    XLONG    (south_north, west_east) float32 ...\n",
      "    level    int64 2500\n",
      "Dimensions without coordinates: south_north, west_east\n",
      "Attributes:\n",
      "    missing_value:  9.969209968386869e+36\n",
      "    _FillValue:     9.969209968386869e+36\n",
      "    vert_units:     None\n"
     ]
    }
   ],
   "source": [
    "# print(ncds_wrf_dbz)\n",
    "# print(ncds_wrf_z.dimensions)\n",
    "# print(type(data_wrf_z_unstag))\n",
    "# print(wrf_dbz)\n",
    "print(dbz_lev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce6c18-4cda-4b5f-b3b7-bf4e1ccd0d19",
   "metadata": {},
   "source": [
    "**Test inserting Z into Netcdf4 dataset (read multiple files at once):\n",
    "NOT WORKING!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b41f8d94-4b9e-4cf7-af36-dce8b38ca779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_names = [ file_name_list['dbz'], file_name_list['Z'] ]\n",
    "# ncds_wrf_dbz_z = MFDataset(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf07d7b-8140-494c-b0eb-8262ce1a9e62",
   "metadata": {},
   "source": [
    "**Test interpolation with xarray data array:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f509b077-4ff4-426e-b35b-8e180ace8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_wrf_dbz = xr.open_dataset(file_name_list['dbz'])\n",
    "\n",
    "data_wrf_z_unstag = wrf.destagger(getvar(Dataset(file_name_list['Z']), 'Z', timeidx=0, meta=False), 0)\n",
    "# print(ds_wrf_z_unstag.shape)\n",
    "# print(type(da_wrf_z_unstag))\n",
    "\n",
    "da_wrf_dbz = ds_wrf_dbz['dBZ'].isel(Time=0).assign_coords(GEO_H=(('bottom_top','south_north','west_east'), data_wrf_z_unstag))\n",
    "\n",
    "# da_wrf_dbz = xr.DataArray( ds_wrf_dbz['dBZ'].isel(Time=0), {'GEO_H': (('bottom_top','south_north','west_east'), da_wrf_z_unstag)} )\n",
    "\n",
    "# da_wrf_dbz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bac53af-2af5-4054-be56-0706342808a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ma.core.MaskedArray'>\n"
     ]
    }
   ],
   "source": [
    "da_wrf_dbz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba73ed-e4ab-4889-8e26-a7f9df4144c5",
   "metadata": {},
   "source": [
    "**Get wrf outputsizeariables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c600816-e8eb-4a48-bf0c-1b3a66b48be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrf_vars(file_name, var_name, time_index):\n",
    "\n",
    "    wrf_file = Dataset(file_name)\n",
    "    # wrf_var = getvar(wrf_file, wrf_var_to_read, timeidx=time_index_1) # This doesn't work for CONUS run files.\n",
    "    wrf_var = getvar(wrf_file, var_name, timeidx=time_index, meta=False)\n",
    "    # wrf_var_time = wrf.extract_times(wrf_file, timeidx=time_index)\n",
    "    # print(wrf_var_time)\n",
    "    \n",
    "    return wrf_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19e33137-a0ef-4949-bae7-bb0fed6237c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrf_dbz = xr.open_dataset(file_name_list['dbz'])\n",
    "# wrf_dbz = Dataset(file_name_list['dbz'])\n",
    "# wrf_z = xr.open_dataset(file_name_list['Z'])\n",
    "# wrf_dbz = get_wrf_vars(file_name_list['dbz'], 'dBZ', 0)\n",
    "# wrf_lon = get_wrf_vars(file_name_list['dbz'], 'XLONG', 0)\n",
    "# wrf_lat = get_wrf_vars(file_name_list['dbz'], 'XLAT', 0)\n",
    "# print(type(wrf_dbz))\n",
    "# print(wrf_dbz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac639f9-67db-4feb-a209-4e4e4bfec135",
   "metadata": {},
   "source": [
    "**Calculation for dBZ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2abb3d6-03c9-4614-a8c6-25962e6cf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wrf_dbz(wrf_pres, wrf_temp, wrf_qv, wrf_qr, wrf_qs, wrf_qg):\n",
    "    \n",
    "    wrf_dbz = dbz(wrf_pres \\\n",
    "                , wrf_temp \\\n",
    "                , wrf_qv \\\n",
    "                , wrf_qr \\\n",
    "                , wrf_qs \\\n",
    "                , wrf_qg \\\n",
    "                # , use_varint=True \\\n",
    "                , use_liqskin=False \\\n",
    "                , meta=True \\\n",
    "                 )\n",
    "    \n",
    "    return wrf_dbz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f51dc-7717-47e4-bcda-c66574c92d70",
   "metadata": {},
   "source": [
    "**Set output file path and name:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7511720e-d0c5-4065-b9db-40eb9467791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_output_name(output_file_datetime):\n",
    "\n",
    "    # output_path = '/glade/u/home/hungjui/2scratch/DATA_WRF_CONUS_1_dBZ_v1.0'\n",
    "    \n",
    "    output_time = pd.to_datetime(output_file_datetime).strftime('%Y%m%d') # If input time type is numpy.datetime64:\n",
    "    \n",
    "    # output_name = output_path + '/wrf3d_d01_dbz_{}.nc'.format(file_date_time.strftime('%Y%m%d%H'))\n",
    "    # output_name = output_path + '/wrf3d_d01_dbz_{}.nc'.format(output_time)\n",
    "    output_name = '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_dbz_{}.nc'.format(output_time)\n",
    "\n",
    "    return output_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a356da-81e0-4462-95b7-6814886ba254",
   "metadata": {},
   "source": [
    "### Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b272ee31-b09e-4612-b587-a76bcee7ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(file_date_time):\n",
    "    \n",
    "    ## Set file datetime:\n",
    "    # file_date_time = dt.datetime(2013, 9, 13, 0, 0, 0, tzinfo=pytz.utc)\n",
    "    print('Processing: {}'.format(file_date_time.strftime('%Y%m%d')), end=' ')\n",
    "    \n",
    "    ## Set input files paths and names:\n",
    "    file_name_dict = set_input_names(file_date_time)\n",
    "\n",
    "    ## Get the 3-hourly time list from P and QRAIN files:\n",
    "    wrf_3hour_list_1 = wrf.extract_times(Dataset(file_name_dict['P']), timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "    wrf_3hour_list_2 = wrf.extract_times(Dataset(file_name_dict['QRAIN']), timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "\n",
    "    ## Set wrf variable list for reflectivity retrieval:\n",
    "    wrf_vars_list = ['P', 'TK', 'QVAPOR', 'QRAIN', 'QSNOW', 'QGRAUP']\n",
    "\n",
    "    ## Set dBZ data array and append calculated data:\n",
    "    # wrf_dbz = xr.zeros_like(wrf_dataset_out['P'])\n",
    "    \n",
    "    for hi in range(len(wrf_3hour_list_1)):\n",
    "        \n",
    "        print(str(hi) + ' | ', end=' ')\n",
    "\n",
    "        ## Get the index for common time in different files (every 3-hour):\n",
    "        common_index_2 = np.intersect1d(wrf_3hour_list_1[hi], wrf_3hour_list_2, return_indices=True)[2][0]\n",
    "\n",
    "        ## Get wrf output variables:\n",
    "        wrf_vars = {}\n",
    "        for vname in wrf_vars_list:\n",
    "\n",
    "            file_name = file_name_dict[vname]\n",
    "\n",
    "            if ( vname in ['QRAIN', 'QGRAUP'] ):\n",
    "                wrf_vars['{}'.format(vname)] = get_wrf_vars(file_name, vname, common_index_2)\n",
    "                # wrf_vars['{}'.format(vname)] = xr.open_dataset(file_name)\n",
    "            else:\n",
    "                wrf_vars['{}'.format(vname)] = get_wrf_vars(file_name, vname, hi)\n",
    "                # wrf_vars['{}'.format(vname)] = xr.open_dataset(file_name)\n",
    "\n",
    "\n",
    "        ## Calculation for dBZ:\n",
    "        wrf_dbz_3hr = calculate_wrf_dbz(wrf_vars['P'],\n",
    "                                        wrf_vars['TK'], \n",
    "                                        wrf_vars['QVAPOR'],\n",
    "                                        wrf_vars['QRAIN'],\n",
    "                                        wrf_vars['QSNOW'],\n",
    "                                        wrf_vars['QGRAUP']\n",
    "                                        ) # .to_dataset()\n",
    "        \n",
    "        # wrf_dbz_3hr = wrf_dbz_3hr.expand_dims({'TimeDim': 8})\n",
    "        # print(wrf_dbz_3hr)\n",
    "        \n",
    "        if ( hi == 0 ):\n",
    "            wrf_dbz = wrf_dbz_3hr\n",
    "        else:\n",
    "            wrf_dbz = xr.concat([wrf_dbz, wrf_dbz_3hr], dim='TimeDim')\n",
    "\n",
    "    # print(wrf_dbz)\n",
    "            \n",
    "    ## Set output dataset:\n",
    "    wrf_dataset_out = xr.open_dataset(file_name_dict['P'])    \n",
    "      \n",
    "    ## Add dBZ to output dataset:\n",
    "    wrf_dataset_out['dBZ'] = (['Time', 'bottom_top', 'south_north', 'west_east'], wrf_dbz)\n",
    "    #print(wrf_dataset_out)\n",
    "    \n",
    "    ## Drop P from the output dataset:\n",
    "    wrf_dataset_out = wrf_dataset_out.drop_vars('P')\n",
    "            \n",
    "    ## Unstagger Z vertical grids:\n",
    "    # wrf_var_Z_unstag = wrf.destagger(getvar(Dataset(file_name_dict['Z']), 'Z', timeidx=hi, meta=False), 0)\n",
    "\n",
    "    ## Get AGL:\n",
    "    # wrf_var_Z_AGL = wrf.g_geoht.get_height_agl(Dataset(file_name_dict['Z']), 'Z', meta=False)\n",
    "\n",
    "    ## Add Z and dBZ into dataset of P:\n",
    "    # wrf_dataset_P_Z_dBZ = xr.open_dataset(file_name_dict['P']).isel(Time = hi)\n",
    "    # wrf_dataset_out = xr.open_dataset(file_name_dict['P'])\n",
    "    # wrf_dataset_out['dBZ'] = (['bottom_top', 'south_north', 'west_east'], wrf_dbz)\n",
    "    \n",
    "    # wrf_dataset_P_Z_dBZ['TK'] = (['bottom_top', 'south_north', 'west_east'], wrf_vars['TK'])\n",
    "    # wrf_dataset_P_Z_dBZ['Z'] = (['bottom_top', 'south_north', 'west_east'], wrf_var_Z_unstag)\n",
    "        \n",
    "    ## Calculate Z using the U.S. standard atmosphere & Hypsometric eqn.:\n",
    "    # Z_standard = mpcalc.pressure_to_height_std((wrf_dataset_P_Z_dBZ['P'].values) * units.units.Pa)\n",
    "    # wrf_dataset_P_Z_dBZ['Z_standard'] = (['bottom_top', 'south_north', 'west_east'], Z_standard)\n",
    "\n",
    "    ## Set coordinates and dimensions:\n",
    "\n",
    "    ## Set output file path and name:\n",
    "    output_path_1 = '/glade/u/home/hungjui/2scratch/DATA_WRF_CONUS_1_dBZ_v1.0/' + wrf_sim_type\n",
    "    # output_path_2 = '/20130913'\n",
    "    output_path_2 = '/{}'.format(file_date_time.strftime('%Y'))\n",
    "    output_file_name = set_output_name(file_date_time)\n",
    "    wrf_dataset_out.to_netcdf(output_path_1 + output_path_2 + output_file_name)\n",
    "        \n",
    "    print('Finish this date.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc087e98-3db1-4f8e-9ee7-994dfc6c2e7e",
   "metadata": {},
   "source": [
    "### Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf47bd92-5581-4af6-8e58-f72e49f4e50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 20051227 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  Finish this date.\n",
      "Processing: 20051228 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  Finish this date.\n",
      "Processing: 20051229 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  Finish this date.\n",
      "Processing: 20051230 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  Finish this date.\n",
      "Processing: 20051231 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  Finish this date.\n",
      "RUNTIME：1141.574093 SEC\n",
      "RUNTIME：19.026235 MIN\n",
      "RUNTIME：0.317104 HOUR\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "## WRF Model Simulation Category:\n",
    "wrf_sim_type = 'CTRL3D'\n",
    "# wrf_sim_type = 'PGW3D'\n",
    "\n",
    "## Loop through a period:\n",
    "target_date_range = pd.date_range(start='2005-12-27', end='2005-12-31', tz=pytz.utc)\n",
    "\n",
    "for dayi in target_date_range:\n",
    "    \n",
    "    main_function(dayi)\n",
    "    #main_calc = delayed(main_function)(dayi)\n",
    "    \n",
    "# main_calc.compute()\n",
    "# main_calc.visualize()\n",
    "\n",
    "end = time.time()\n",
    "print(\"RUNTIME：%f SEC\" % (end - start))\n",
    "print(\"RUNTIME：%f MIN\" % ((end - start)/60))\n",
    "print(\"RUNTIME：%f HOUR\" % ((end - start)/3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "689c4e20-46d1-4459-8d88-b906999deee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464604e-9068-4b01-b4f3-d462bbfec819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

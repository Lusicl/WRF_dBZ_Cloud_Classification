{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869fb837-0d1f-4790-9318-8aff52b75ef9",
   "metadata": {},
   "source": [
    "## Retrieve 3D Reflectivity from WRF Simulations using WRF-Python. \n",
    "\n",
    "**For [High Resolution WRF Simulations of the Current and Future Climate of North America](https://rda.ucar.edu/datasets/ds612.0/).**\n",
    "\n",
    "**Hungjui Yu 20210817**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70de2b4e-ad2a-429f-ad4d-c27561e36fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import sys\n",
    "import time\n",
    "import datetime as dt\n",
    "import pytz\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import wrf\n",
    "from wrf import (getvar, dbz, extract_times, destagger)\n",
    "# import metpy\n",
    "# import metpy.calc as mpcalc\n",
    "# import metpy.units as units\n",
    "# print(metpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f64af1f-a06e-4f86-a90c-a20ba4da7ad3",
   "metadata": {},
   "source": [
    "**Set input files paths and names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f06ea2c-4b38-4bdc-9459-a47621e73e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_names(file_date):\n",
    "\n",
    "    file_path_1 = '/gpfs/fs1/collections/rda/data/ds612.0'\n",
    "    file_path_2 = '/CTRL3D'\n",
    "    file_path_3 = '/{}'.format(file_date.strftime('%Y'))\n",
    "\n",
    "    file_names = dict( P = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_P_{}.nc'.format(file_date.strftime('%Y%m%d')) \\\n",
    "                     , TK = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_TK_{}.nc'.format(file_date.strftime('%Y%m%d')) \\\n",
    "                     , QVAPOR = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_QVAPOR_{}.nc'.format(file_date.strftime('%Y%m%d')) \\\n",
    "                     , QRAIN = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_QRAIN_{}.nc'.format(file_date.strftime('%Y%m')) \\\n",
    "                     , QSNOW = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_QSNOW_{}.nc'.format(file_date.strftime('%Y%m%d')) \\\n",
    "                     , QGRAUP = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_QGRAUP_{}.nc'.format(file_date.strftime('%Y%m')) \\\n",
    "                     , Z = file_path_1 + file_path_2 + file_path_3 + '/wrf3d_d01_CTRL_Z_{}.nc'.format(file_date.strftime('%Y%m%d')) \\\n",
    "                     )\n",
    "    \n",
    "    return file_names\n",
    "\n",
    "# file_name_list = set_file_paths_names(file_date_time)\n",
    "# print(file_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba73ed-e4ab-4889-8e26-a7f9df4144c5",
   "metadata": {},
   "source": [
    "**Get wrf output variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c600816-e8eb-4a48-bf0c-1b3a66b48be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wrf_vars(file_name, var_name, time_index):\n",
    "\n",
    "    wrf_file = Dataset(file_name)\n",
    "    # wrf_var = getvar(wrf_file, wrf_var_to_read, timeidx=time_index_1) # This doesn't work for CONUS run files.\n",
    "    wrf_var = getvar(wrf_file, var_name, timeidx=time_index, meta=False)\n",
    "    # wrf_var_time = wrf.extract_times(wrf_file, timeidx=time_index)\n",
    "    # print(wrf_var_time)\n",
    "    \n",
    "    return wrf_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac639f9-67db-4feb-a209-4e4e4bfec135",
   "metadata": {},
   "source": [
    "**Calculation for dBZ:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2abb3d6-03c9-4614-a8c6-25962e6cf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wrf_dbz(wrf_pres, wrf_temp, wrf_qv, wrf_qr, wrf_qs, wrf_qg):\n",
    "    \n",
    "    wrf_dbz = dbz(wrf_pres \\\n",
    "                , wrf_temp \\\n",
    "                , wrf_qv \\\n",
    "                , wrf_qr \\\n",
    "                , wrf_qs \\\n",
    "                , wrf_qg \\\n",
    "                # , use_varint=True \\\n",
    "                , use_liqskin=False \\\n",
    "                , meta=True \\\n",
    "                 )\n",
    "    \n",
    "    return wrf_dbz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f51dc-7717-47e4-bcda-c66574c92d70",
   "metadata": {},
   "source": [
    "**Set output file path and name:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7511720e-d0c5-4065-b9db-40eb9467791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_output_name(file_date_time):\n",
    "\n",
    "    # output_path = '/glade/u/home/hungjui/2scratch/DATA_WRF_CONUS_1_dBZ_v1.0'\n",
    "    \n",
    "    output_time = pd.to_datetime(wrf_3hour_list_1[hi]).strftime('%Y%m%d%H') # If input time type is numpy.datetime64:\n",
    "    \n",
    "    # output_name = output_path + '/wrf3d_d01_dbz_{}.nc'.format(file_date_time.strftime('%Y%m%d%H'))\n",
    "    # output_name = output_path + '/wrf3d_d01_dbz_{}.nc'.format(output_time)\n",
    "    output_name = '/wrf3d_d01_dbz_{}.nc'.format(output_time)\n",
    "\n",
    "    return output_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc087e98-3db1-4f8e-9ee7-994dfc6c2e7e",
   "metadata": {},
   "source": [
    "### Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf47bd92-5581-4af6-8e58-f72e49f4e50c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'month' is an invalid keyword argument for __new__()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a8e17cc8aaa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mwrf_3hour_list_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_date_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'3H'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m wrf_3hour_list_2 = pd.date_range(start = str(file_date_time.year) + '-' + str(file_date_time.month) + '-1'\n\u001b[0;32m---> 19\u001b[0;31m                                 \u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_date_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_date_time\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                                 ,freq = '3H')\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'month' is an invalid keyword argument for __new__()"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "## WRF Model Simulation Category:\n",
    "wrf_sim_type = 'CTRL3D'\n",
    "\n",
    "## Set file datetime:\n",
    "file_date_time = dt.datetime(2013, 9, 13, 0, 0, 0, tzinfo=pytz.utc)\n",
    "\n",
    "## Set input files paths and names:\n",
    "file_name_dict = set_input_names(file_date_time)\n",
    "\n",
    "## Get the 3-hourly time list from P and QRAIN files:\n",
    "wrf_3hour_list_1 = wrf.extract_times(Dataset(file_name_dict['P']), timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "wrf_3hour_list_2 = wrf.extract_times(Dataset(file_name_dict['QRAIN']), timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "\n",
    "## Set wrf variable list for reflectivity retrieval:\n",
    "wrf_vars_list = ['P', 'TK', 'QVAPOR', 'QRAIN', 'QSNOW', 'QGRAUP']\n",
    "\n",
    "for hi in range(len(wrf_3hour_list_1)):\n",
    "    \n",
    "    ## Get the index for common time in different files (every 3-hour):\n",
    "    common_index_2 = np.intersect1d(wrf_3hour_list_1[hi], wrf_3hour_list_2, return_indices=True)[2][0]\n",
    "    \n",
    "    ## Get wrf output variables:\n",
    "    wrf_vars = {}\n",
    "    for vname in wrf_vars_list:\n",
    "        \n",
    "        file_name = file_name_dict[vname]\n",
    "        \n",
    "        if ( vname in ['QRAIN', 'QGRAUP'] ):\n",
    "            wrf_vars['{}'.format(vname)] = get_wrf_vars(file_name, vname, common_index_2)\n",
    "            # wrf_vars['{}'.format(vname)] = xr.open_dataset(file_name)\n",
    "        else:\n",
    "            wrf_vars['{}'.format(vname)] = get_wrf_vars(file_name, vname, hi)\n",
    "            # wrf_vars['{}'.format(vname)] = xr.open_dataset(file_name)\n",
    "    \n",
    "    \n",
    "    ## Calculation for dBZ:\n",
    "    wrf_dbz = calculate_wrf_dbz(wrf_vars['P'],\n",
    "                                wrf_vars['TK'], \n",
    "                                wrf_vars['QVAPOR'],\n",
    "                                wrf_vars['QRAIN'],\n",
    "                                wrf_vars['QSNOW'],\n",
    "                                wrf_vars['QGRAUP']\n",
    "                                ) # .to_dataset()\n",
    "    \n",
    "    ## Unstagger Z vertical grids:\n",
    "    wrf_dataset_Z = Dataset(file_name_dict['Z'])\n",
    "    wrf_var_Z = getvar(wrf_dataset_Z, 'Z', timeidx=hi, meta=False)\n",
    "    wrf_var_Z_unstag = wrf.destagger(wrf_var_Z, 0)\n",
    "    \n",
    "    ## Add Z and dBZ into dataset of P (option: with calculated Z using the U.S. standard atmosphere:\n",
    "    wrf_dataset_P_Z_dBZ = xr.open_dataset(file_name_dict['P']).isel(Time = hi)\n",
    "    wrf_dataset_P_Z_dBZ['Z'] = (['bottom_top', 'south_north', 'west_east'], wrf_var_Z_unstag)\n",
    "    wrf_dataset_P_Z_dBZ['dBZ'] = (['bottom_top', 'south_north', 'west_east'], wrf_dbz)\n",
    "    \n",
    "    # Z_standard = mpcalc.pressure_to_height_std((wrf_dataset_P_Z_dBZ['P'].values) * units.units.Pa)\n",
    "    # wrf_dataset_P_Z_dBZ['Z_standard'] = (['bottom_top', 'south_north', 'west_east'], Z_standard)\n",
    "    \n",
    "    ## Set coordinates and dimensions:\n",
    "    \n",
    "    ## Set output file path and name:\n",
    "    output_path = '/glade/u/home/hungjui/2scratch/DATA_WRF_CONUS_1_dBZ_v1.0/' + wrf_sim_type\n",
    "    output_file_name = set_output_name(wrf_3hour_list_1[hi])\n",
    "    wrf_dataset_P_Z_dBZ.to_netcdf(output_path + output_file_name)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"RUNTIME：%f SEC\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c487b696-e06b-4d51-af82-b83cedc9f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-09-30 00:00:00+00:00\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "# print(file_date_time. + pd.offsets.MonthEnd(1))\n",
    "# print(type(file_date_time))\n",
    "# wrf_3hour_list_1[1]\n",
    "# wrf_dataset_P_Z_dBZ\n",
    "# type(wrf_dbz)\n",
    "# wrf_dbz.rename({'dim_0': 'bottom_top', 'dim_1': 'south_north', 'dim_2': 'west_east'})\n",
    "# wrf_dbz.dims\n",
    "# wrf_data = xr.open_dataset(file_name_dict['P'])\n",
    "# wrf_data\n",
    "# xr.open_dataset(file_name_dict['P']).coords\n",
    "# wrf_data.coords['Time']\n",
    "# vvv = wrf_dbz.dims\n",
    "# type(vvv)\n",
    "# print(vvv)\n",
    "# tmp_wrf_file = Dataset(file_name_dict['P'])\n",
    "# tmp_var = getvar(tmp_wrf_file, 'P', 0)\n",
    "# wrf.latlon_coordvars(tmp_var)\n",
    "# print(tmp_wrf_file['XLAT'][:,1])\n",
    "# print(tmp_wrf_file['XLAT'][:,2])\n",
    "# tmp_xlong = getvar(tmp_wrf_file, 'XLONG', 0, meta=False)\n",
    "# print(tmp_xlong.shape)\n",
    "# print(tmp_xlong)\n",
    "# wrf_dims = wrf.extract_dim(Dataset(file_name_dict['P']))\n",
    "# print(wrf_dims)\n",
    "# print(wrf_vars)\n",
    "# print(type(wrf_dbz))\n",
    "# print(type(wrf_vars['P']))\n",
    "# print(wrf_dbz.dims)\n",
    "# print(type(wrf_3hour_list_1[hi]))\n",
    "# print(wrf_3hour_list_1[hi])\n",
    "# output_time = pd.to_datetime(wrf_3hour_list_1[hi]).strftime('%Y%m%d%H')\n",
    "# print(output_time)\n",
    "# tmp_t = dt.datetime.utcfromtimestamp((wrf_3hour_list_1[hi]-np.datetime64('1970-01-01T00:00:00Z')) / np.timedelta64(1, 's'))\n",
    "# print(tmp_t)\n",
    "# print(wrf_vars['P'])\n",
    "# print(type(wrf_3hour_list_1[hi]))\n",
    "# print(common_index)\n",
    "# print(wrf_3hour_list)\n",
    "# print(file_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82543c9c-4b5c-45d9-937f-e2339a443dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

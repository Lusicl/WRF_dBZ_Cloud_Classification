{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869fb837-0d1f-4790-9318-8aff52b75ef9",
   "metadata": {},
   "source": [
    "## Storm Mode/Precipitation Type Classification Output for 3D Reflectivity from derived dBZ of WRF Simulations. \n",
    "\n",
    "**Based on the Convective/Stratiform separation on the 12 $\\sigma$ level of reflectivity.**\n",
    "\n",
    "**Calculate the max. composite reflectivity instead of REFLC_10CM from CONUS1 runs.**\n",
    "\n",
    "**Storm Mode Classification starts from the Composite dBZ (Rain Area) identification, and add another mode: Shallow (Non-Deep) Convective Cores (SCC) to represent shallow conveciton.**\n",
    "\n",
    "**Output the Storm Mode Classification information (1:DCC; 2:SCC; 3:WCC; 4:DWCC; 5:BSR) to CONUS dBZ data.**\n",
    "\n",
    "**For [High Resolution WRF Simulations of the Current and Future Climate of North America](https://rda.ucar.edu/datasets/ds612.0/).**\n",
    "\n",
    "**Hungjui Yu 20211029**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70de2b4e-ad2a-429f-ad4d-c27561e36fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from shutil import copyfile\n",
    "import time\n",
    "import datetime as dt\n",
    "# import pytz\n",
    "from netCDF4 import Dataset # MFDataset\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, generate_binary_structure\n",
    "import xarray as xr\n",
    "import wrf\n",
    "from wrf import (getvar, interplevel, destagger)\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeat\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc002f5-0b9b-4623-9125-4bbc79e62cb1",
   "metadata": {},
   "source": [
    "**Set input files paths and names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ab40b2-64cb-4afa-a31e-27ffe4a06475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_names(file_date):\n",
    "\n",
    "    file_path_1_conus = '/gpfs/fs1/collections/rda/data/ds612.0'\n",
    "    file_path_1_dbz = '/glade/scratch/hungjui/DATA_WRF_CONUS_1_dBZ_v1.0'\n",
    "    file_path_2 = '/' + wrf_sim_type # '/CTRL3D'\n",
    "    file_path_3 = '/{}'.format(file_date.strftime('%Y'))\n",
    "\n",
    "    file_names = dict( dbz = file_path_1_dbz\n",
    "                           + file_path_2 \n",
    "                           + '/20130913'# file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_dbz_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                       , Z = file_path_1_conus\n",
    "                           + file_path_2 \n",
    "                           + file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_Z_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                     )\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75677bd1-dd53-408c-be0d-c8e284ee9652",
   "metadata": {},
   "source": [
    "**Function: Reflectivity Geo-Height Interpolation (linearly):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "184f6d7d-f88a-447f-b1b8-c498f04a1320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbz_geoh_interp(refl, geoH, interp_lev_km):\n",
    "    \n",
    "    # # Use linear Z for interpolation:\n",
    "    refl_linear = 10**(refl/10.)\n",
    "    \n",
    "    ## Interpolation:\n",
    "    ## !!! convert interpolation level to the same as geo-H (meter) !!!\n",
    "    refl_linear_lev = interplevel(refl_linear, geoH, interp_lev_km*1000)\n",
    "    \n",
    "    ## Convert back to dBz after interpolation:\n",
    "    refl_lev = 10.0 * np.log10(refl_linear_lev)\n",
    "    \n",
    "    return refl_lev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786984b-bc1d-4e30-97c4-c00dc8036faf",
   "metadata": {},
   "source": [
    "**Function: Set Storm Mode Classification Thresholds:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d56943-6e93-4dea-a42e-2faeed767c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_classification_thresholds(threshold_type):\n",
    "    \n",
    "    ## Make sure the thresholds are either Mocderate or Strong:\n",
    "    assert threshold_type in ['moderate', 'strong']\n",
    "    \n",
    "    if ( threshold_type == 'moderate' ):\n",
    "        dbz_threshold = 30 # dBZ\n",
    "        height_threshold = 8 # km\n",
    "        WCC_threshold = 800 # km^2\n",
    "        BSR_threshold = 40000 # km^2\n",
    "    else:\n",
    "        dbz_threshold = 40 # dBZ\n",
    "        height_threshold = 10 # km\n",
    "        WCC_threshold = 1000 # km^2\n",
    "        BSR_threshold = 50000 # km^2\n",
    "        \n",
    "    return dbz_threshold, height_threshold, WCC_threshold, BSR_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26640f-93ae-47ff-8c0a-a7f6673021ad",
   "metadata": {},
   "source": [
    "**Function: Storm Mode Classification:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b161acd3-1bcb-4574-a36d-bad7c1f58e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storm_mode_class( refl, reflc, CS_mask\n",
    "                    , geoH\n",
    "                    , resolution_WRF = 4 # km grid spacing \n",
    "                    , threshold_type\n",
    "                    # , dbz_threshold # dBZ\n",
    "                    # , height_threshold # km\n",
    "                    # , WCC_threshold # km^2\n",
    "                    # , BSR_threshold # km^2\n",
    "                    ):\n",
    "    \n",
    "    ## ======================================================================\n",
    "    ## \n",
    "    ## Run:     storm_mode_class(da_wrf_dbz, da_wrf_reflc, da_wrf_CSmask, data_wrf_z_unstag)\n",
    "    ## \n",
    "    ## Input:\n",
    "    ## refl:    Derived 3D reflectivity\n",
    "    ## reflc:   Derived 2D max. reflectivity composite\n",
    "    ## CS_mask: 2D Convective/Stratifom mask at 12th sigma level (~1.5–2km agl.)\n",
    "    ## geoH:    3D Geopotential-height (msl. in meter)\n",
    "    ##\n",
    "    ## ======================================================================\n",
    "    \n",
    "    ## Set thresholds:\n",
    "    dbz_threshold, height_threshold, WCC_threshold, BSR_threshold = set_classification_thresholds(threshold_type)\n",
    "    \n",
    "    ## Set pixel numbers required for WCC & BSR:\n",
    "    WCC_pixels_required = WCC_threshold/(resolution_WRF**2)\n",
    "    BSR_pixels_required = BSR_threshold/(resolution_WRF**2)\n",
    "    \n",
    "    ## Interpolate reflectivity to height threshold:\n",
    "    refl_lev = dbz_geoh_interp(refl, geoH, height_threshold)\n",
    "    \n",
    "    ## Generate a structuring element that will consider features connected even if they touch diagonally:\n",
    "    se = generate_binary_structure(2, 2)\n",
    "    \n",
    "    \n",
    "    ## ======================================================================\n",
    "    ## 1:\n",
    "    ## Threshold - Max. Composite dBZ & Convective Mask:\n",
    "    reflc_boo_tmp = np.where( (reflc >= dbz_threshold) & (CS_mask > 0), 1, 0 )\n",
    "    \n",
    "    ## DCC & SCC masking:\n",
    "    DCC_mask = np.where( ((reflc_boo_tmp == 1) & (refl_lev >= dbz_threshold)), 1, 0 )\n",
    "    SCC_mask = np.where( ((reflc_boo_tmp == 1) & (refl_lev < dbz_threshold)), 1, 0 )\n",
    "    \n",
    "    \n",
    "    ## ======================================================================\n",
    "    ## 2:\n",
    "    ## WCC & DWCC masking:\n",
    "    labeled_array_reflc_boo, num_features_reflc_boo = label( reflc_boo_tmp, structure=se )\n",
    "    \n",
    "    WCC_mask = np.zeros_like(labeled_array_reflc_boo)\n",
    "    DWCC_mask = np.zeros_like(labeled_array_reflc_boo)\n",
    "\n",
    "    for feati in np.arange(num_features_reflc_boo):\n",
    "        feat_id = feati+1\n",
    "        if ( (labeled_array_reflc_boo == feat_id).sum() > WCC_pixels_required ):\n",
    "            if ( (DCC_mask[np.where(labeled_array_reflc_boo == feat_id)]).sum() == 0 ):\n",
    "                WCC_mask = np.where( (labeled_array_reflc_boo == feat_id), 1, WCC_mask )\n",
    "            else:\n",
    "                DWCC_mask = np.where( (labeled_array_reflc_boo == feat_id), 1, DWCC_mask )\n",
    "            \n",
    "    \n",
    "    ## ======================================================================\n",
    "    ## 3:\n",
    "    ## DCC mask adjustment for DWCC:\n",
    "    DCC_mask[np.where(DWCC_mask == 1)] = 0\n",
    "    \n",
    "    ## SCC mask adjustment for WCC and DWCC:\n",
    "    SCC_mask[np.where( (WCC_mask) | (DWCC_mask == 1) )] = 0\n",
    "        \n",
    "    ## ======================================================================\n",
    "    ## 4:\n",
    "    ## Threshold - Stratiform Mask:\n",
    "    stratiform_boo_tmp = np.where( (CS_mask == 0), 1, 0 )\n",
    "    \n",
    "    ## BSR masking:\n",
    "    labeled_array_BSR, num_features_BSR = label( stratiform_boo_tmp, structure=se )\n",
    "    \n",
    "    BSR_mask = np.zeros_like(labeled_array_BSR)\n",
    "\n",
    "    for feati in np.arange(num_features_BSR):\n",
    "        feat_id = feati+1\n",
    "        if ( (labeled_array_BSR==feat_id).sum() > BSR_pixels_required ):\n",
    "            BSR_mask = np.where( (labeled_array_BSR==feat_id), 1, BSR_mask )\n",
    "    \n",
    "    \n",
    "    return DCC_mask, SCC_mask, WCC_mask, DWCC_mask, BSR_mask\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7fd64-c359-428c-af60-e9fdb290dfdc",
   "metadata": {},
   "source": [
    "**Function: Merge masks to Storm Modes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e83647-65a9-417c-b8ed-2fd9dc186268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_to_Storm_Mode( DCC_mask\n",
    "                       , SCC_mask\n",
    "                       , WCC_mask\n",
    "                       , DWCC_mask\n",
    "                       , BSR_mask\n",
    "                       ):\n",
    "    \n",
    "    Storm_Mode = np.zeros_like(DCC_mask)\n",
    "    Storm_Mode = np.where( (DCC_mask==1), 1, Storm_Mode )\n",
    "    Storm_Mode = np.where( (SCC_mask==1), 2, Storm_Mode )\n",
    "    Storm_Mode = np.where( (WCC_mask==1), 3, Storm_Mode )\n",
    "    Storm_Mode = np.where( (DWCC_mask==1), 4, Storm_Mode )\n",
    "    Storm_Mode = np.where( (BSR_mask==1), 5, Storm_Mode )\n",
    "\n",
    "    # Storm_Mode[np.where(Storm_Mode == 0)] = np.nan\n",
    "    \n",
    "    return Storm_Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a356da-81e0-4462-95b7-6814886ba254",
   "metadata": {},
   "source": [
    "### Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650a17a6-11f4-4833-b901-7559cec8dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(file_date_time):\n",
    "    \n",
    "    ## Set file datetime:\n",
    "    # file_date_time = dt.datetime(2013, 9, 13, 0, 0, 0, tzinfo=pytz.utc)\n",
    "    print('\\nProcessing: {}'.format(file_date_time.strftime('%Y%m%d')), end=': ')\n",
    "    \n",
    "    ## Set input files paths and names:\n",
    "    file_name_dict = set_input_names(file_date_time)\n",
    "\n",
    "    ## Get the 3-hourly time list:\n",
    "    nc_wrf_Z = Dataset(file_name_dict['Z'], mode='r')\n",
    "    wrf_3hour_list = wrf.extract_times(nc_wrf_Z, timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "    \n",
    "    ## Open dBZ data array and append calculated data:\n",
    "    ds_wrf_dbz = xr.open_dataset(file_name_dict['dbz'])\n",
    "    \n",
    "    for hi in range(len(wrf_3hour_list)):\n",
    "        \n",
    "        print(str(hi) + ' | ', end=' ')\n",
    "\n",
    "        ## Get dBZ data:\n",
    "        da_wrf_dbz = ds_wrf_dbz['dBZ'].isel(Time=hi)\n",
    "        da_wrf_CSmask = ds_wrf_dbz['CS_mask'].isel(Time=hi)\n",
    "\n",
    "        ## Calculate the max. composite dBZ:\n",
    "        da_wrf_reflc = da_wrf_dbz.max(dim='bottom_top')\n",
    "\n",
    "        ## Get geopotential height:\n",
    "        data_wrf_z_unstag = wrf.destagger(getvar(nc_wrf_Z), 'Z', timeidx=hi, meta=False), 0)\n",
    "        \n",
    "        ## Storm Mode Classification (moderate thresholds):\n",
    "        dbz_threshold, height_threshold, WCC_threshold, BSR_threshold = \n",
    "        \n",
    "        DCC_mask, SCC_mask, WCC_mask, DWCC_mask, BSR_mask = storm_mode_class( da_wrf_dbz\n",
    "                                                                            , da_wrf_reflc\n",
    "                                                                            , da_wrf_CSmask\n",
    "                                                                            , data_wrf_z_unstag\n",
    "                                                                            , 'moderate'\n",
    "                                                                            )\n",
    "        Storm_Mode_single_m = merge_to_Storm_Mode( DCC_mask, SCC_mask, WCC_mask, DWCC_mask, BSR_mask )\n",
    "        \n",
    "        ## Storm Mode Classification (strong thresholds):\n",
    "        dbz_threshold, height_threshold, WCC_threshold, BSR_threshold = \n",
    "        \n",
    "        DCC_mask, SCC_mask, WCC_mask, DWCC_mask, BSR_mask = storm_mode_class( da_wrf_dbz\n",
    "                                                                            , da_wrf_reflc\n",
    "                                                                            , da_wrf_CSmask\n",
    "                                                                            , data_wrf_z_unstag\n",
    "                                                                            , 'strong'\n",
    "                                                                            )\n",
    "        Storm_Mode_single_s = merge_to_Storm_Mode( DCC_mask, SCC_mask, WCC_mask, DWCC_mask, BSR_mask )\n",
    "        \n",
    "        ## Stack the Storm Mode according to hours:\n",
    "        if ( hi == 0 ):\n",
    "            Storm_Mode_m = np.expand_dims(Storm_Mode_single_m, axis=0)\n",
    "            Storm_Mode_s = np.expand_dims(Storm_Mode_single_s, axis=0)\n",
    "        else:\n",
    "            Storm_Mode_m = np.append(Storm_Mode_m, np.expand_dims(Storm_Mode_single_m, axis=0), axis=0)\n",
    "            Storm_Mode_s = np.append(Storm_Mode_s, np.expand_dims(Storm_Mode_single_s, axis=0), axis=0)\n",
    "            \n",
    "    ## Add Storm Mode to dBZ dataset:\n",
    "    ds_wrf_dbz['Storm_Mode_m'] = (['Time', 'south_north', 'west_east'], Storm_Mode_m)\n",
    "    ds_wrf_dbz['Storm_Mode_s'] = (['Time', 'south_north', 'west_east'], Storm_Mode_s)\n",
    "    \n",
    "    ds_wrf_dbz.close()\n",
    "    \n",
    "    nc_wrf_Z.close()\n",
    "    \n",
    "    return ds_wrf_dbz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc087e98-3db1-4f8e-9ee7-994dfc6c2e7e",
   "metadata": {},
   "source": [
    "### Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72815f7e-3b87-4c09-91d1-34614c269e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 20130912: 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  RUNTIME：72.465595 SEC\n",
      "RUNTIME：1.207760 MIN\n",
      "RUNTIME：0.020129 HOUR\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "## WRF Model Simulation Category:\n",
    "wrf_sim_type = 'CTRL3D'\n",
    "# wrf_sim_type = 'PGW3D'\n",
    "\n",
    "## Loop through a period:\n",
    "target_date_range = pd.date_range(start='2013-9-13', end='2013-9-13', tz=pytz.utc)\n",
    "\n",
    "for dayi in target_date_range:\n",
    "        \n",
    "    ## Derive Convective/Stratiform mask into dBZ dataset:\n",
    "    ds_wrf_dbz = main_function(dayi)\n",
    "    \n",
    "    ## Add attributes to Storm Mode:\n",
    "    ds_wrf_dbz.Storm_Mode_m.attrs['long_name'] = 'Storm Mode (moderate thresholds)'\n",
    "    ds_wrf_dbz.Storm_Mode_m.attrs['description'] = 'Classified Storm Modes with moderate thresholds (1:DCC; 2:SCC; 3:WCC; 4:DWCC; 5:BSR)'\n",
    "    \n",
    "    ds_wrf_dbz.Storm_Mode_s.attrs['long_name'] = 'Storm Mode (strong thresholds)'\n",
    "    ds_wrf_dbz.Storm_Mode_s.attrs['description'] = 'Classified Storm Modes with strong thresholds (1:DCC; 2:SCC; 3:WCC; 4:DWCC; 5:BSR)'\n",
    "    \n",
    "    ## Set output file path and name (to the original dBZ dataset):\n",
    "    file_name_dict = set_input_names(dayi)\n",
    "    file_path_name = file_name_dict['dbz']\n",
    "    \n",
    "    ds_wrf_dbz.to_netcdf(file_path_name, 'a')\n",
    "    ds_wrf_dbz.close()\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"RUNTIME：%f SEC\" % (end - start))\n",
    "print(\"RUNTIME：%f MIN\" % ((end - start)/60))\n",
    "print(\"RUNTIME：%f HOUR\" % ((end - start)/3600))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689c4e20-46d1-4459-8d88-b906999deee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02242753-fdbe-4aee-8118-749c04a9f8c7",
   "metadata": {},
   "source": [
    "<font color='teal'>**Supplement Codes:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6753ca-b044-4675-85a3-4bae42cddd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from netCDF4 import (Dataset, MFDataset)\n",
    "# nc_wrf_dbz = Dataset( '/glade/scratch/hungjui/DATA_WRF_CONUS_1_dBZ_v1.0/CTRL3D/20130913/wrf3d_d01_CTRL_dbz_20130913.nc'\n",
    "#                     , mode='a')\n",
    "# # nc_wrf_dbz.createDimension('test_dim', 1)\n",
    "# print(nc_wrf_dbz)\n",
    "# nc_wrf_dbz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02c71f-4503-4196-a9f5-f592599ea4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

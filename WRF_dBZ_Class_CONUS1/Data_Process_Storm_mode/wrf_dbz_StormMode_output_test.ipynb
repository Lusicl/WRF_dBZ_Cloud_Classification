{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869fb837-0d1f-4790-9318-8aff52b75ef9",
   "metadata": {},
   "source": [
    "## Storm Mode/Precipitation Type Classification Output for 3D Reflectivity from derived dBZ of WRF Simulations. \n",
    "\n",
    "**Based on the Convective/Stratiform separation on the 12 $\\sigma$ level of reflectivity.**\n",
    "\n",
    "**Calculate the max. composite reflectivity instead of REFLC_10CM from CONUS1 runs.**\n",
    "\n",
    "**Storm Mode Classification starts from the Composite dBZ (Rain Area) identification, and add another mode: Ordinary (Non-Deep) Convective Cores (OCC) to represent shallow conveciton.**\n",
    "\n",
    "**Output the Storm Mode Classification information (1:DCC; 2:OCC; 3:WCC; 4:DWCC; 5:BSR) to CONUS dBZ data.**\n",
    "\n",
    "**For [High Resolution WRF Simulations of the Current and Future Climate of North America](https://rda.ucar.edu/datasets/ds612.0/).**\n",
    "\n",
    "**Hungjui Yu 20211105**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "70de2b4e-ad2a-429f-ad4d-c27561e36fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# from shutil import copyfile\n",
    "import time\n",
    "# import datetime as dt\n",
    "import pytz\n",
    "from netCDF4 import Dataset # MFDataset\n",
    "import numpy as np\n",
    "# from scipy.ndimage import label, generate_binary_structure\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import wrf\n",
    "from wrf import (getvar, interplevel, destagger)\n",
    "\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeat\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "modules_path = '/glade/work/hungjui/Research_Test/WRF_dBZ_Cloud_Classification/WRF_dBZ_Class_CONUS1/Modules'\n",
    "if ( modules_path not in sys.path ):\n",
    "    sys.path = [modules_path] + sys.path\n",
    "    # print(sys.path)\n",
    "    \n",
    "import storm_mode_class5 as stm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc002f5-0b9b-4623-9125-4bbc79e62cb1",
   "metadata": {},
   "source": [
    "**Set input files paths and names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1ab40b2-64cb-4afa-a31e-27ffe4a06475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_names(file_date):\n",
    "\n",
    "    file_path_1_conus = '/gpfs/fs1/collections/rda/data/ds612.0'\n",
    "    file_path_1_dbz = '/glade/scratch/hungjui/DATA_WRF_CONUS_1_dBZ_v1.0'\n",
    "    file_path_2 = '/' + wrf_sim_type # '/CTRL3D'\n",
    "    file_path_3 = '/{}'.format(file_date.strftime('%Y'))\n",
    "\n",
    "    file_names = dict( dbz = file_path_1_dbz\n",
    "                           + file_path_2 \n",
    "                           + '/20110427' # '/20130913'# file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_dbz_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                       , Z = file_path_1_conus\n",
    "                           + file_path_2 \n",
    "                           + file_path_3 \n",
    "                           + '/wrf3d_d01_' + wrf_sim_type[0:-2] + '_Z_{}.nc'.format(file_date.strftime('%Y%m%d'))\n",
    "                     )\n",
    "    \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a356da-81e0-4462-95b7-6814886ba254",
   "metadata": {},
   "source": [
    "### Main Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "650a17a6-11f4-4833-b901-7559cec8dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(file_date_time):\n",
    "    \n",
    "    ## Set file datetime:\n",
    "    # file_date_time = dt.datetime(2013, 9, 13, 0, 0, 0, tzinfo=pytz.utc)\n",
    "    print('\\nProcessing: {}'.format(file_date_time.strftime('%Y%m%d')), end=': ')\n",
    "    \n",
    "    ## Set input files paths and names:\n",
    "    file_name_dict = set_input_names(file_date_time)\n",
    "\n",
    "    ## Get the 3-hourly time list:\n",
    "    nc_wrf_Z = Dataset(file_name_dict['Z'], mode='r')\n",
    "    wrf_3hour_list = wrf.extract_times(nc_wrf_Z, timeidx=wrf.ALL_TIMES, meta=False, do_xtime=False)\n",
    "    \n",
    "    ## Open dBZ data array and append calculated data:\n",
    "    ds_wrf_dbz = xr.open_dataset(file_name_dict['dbz'])\n",
    "    \n",
    "    for hi in range(len(wrf_3hour_list)):\n",
    "        \n",
    "        print(str(hi) + ' | ', end=' ')\n",
    "\n",
    "        ## Get dBZ data:\n",
    "        da_wrf_dbz = ds_wrf_dbz['dBZ'].isel(Time=hi)\n",
    "        da_wrf_CSmask = ds_wrf_dbz['CS_mask'].isel(Time=hi)\n",
    "\n",
    "        ## Calculate the max. composite dBZ:\n",
    "        da_wrf_reflc = da_wrf_dbz.max(dim='bottom_top')\n",
    "\n",
    "        ## Get geopotential height:\n",
    "        data_wrf_z_unstag = wrf.destagger(getvar(nc_wrf_Z, 'Z', timeidx=hi, meta=False), 0)\n",
    "        \n",
    "        ## Storm Mode Classification (moderate thresholds):\n",
    "        DCC_mask, OCC_mask, WCC_mask, DWCC_mask, BSR_mask = stm.storm_mode_c5( da_wrf_dbz\n",
    "                                                                             , da_wrf_reflc\n",
    "                                                                             , da_wrf_CSmask\n",
    "                                                                             , data_wrf_z_unstag\n",
    "                                                                             , 4 # 4-km grid resolution\n",
    "                                                                             , 'moderate'\n",
    "                                                                             )\n",
    "        Storm_Mode_single_m = stm.merge_to_Storm_Mode(DCC_mask, OCC_mask, WCC_mask, DWCC_mask, BSR_mask)\n",
    "        \n",
    "        ## Storm Mode Classification (strong thresholds):\n",
    "        DCC_mask, OCC_mask, WCC_mask, DWCC_mask, BSR_mask = stm.storm_mode_c5( da_wrf_dbz\n",
    "                                                                             , da_wrf_reflc\n",
    "                                                                             , da_wrf_CSmask\n",
    "                                                                             , data_wrf_z_unstag\n",
    "                                                                             , 4 # 4-km grid resolution\n",
    "                                                                             , 'strong'\n",
    "                                                                             )\n",
    "        Storm_Mode_single_s = stm.merge_to_Storm_Mode(DCC_mask, OCC_mask, WCC_mask, DWCC_mask, BSR_mask)\n",
    "        \n",
    "        ## Stack the Storm Mode according to hours:\n",
    "        if ( hi == 0 ):\n",
    "            Storm_Mode_m = np.expand_dims(Storm_Mode_single_m, axis=0)\n",
    "            Storm_Mode_s = np.expand_dims(Storm_Mode_single_s, axis=0)\n",
    "        else:\n",
    "            Storm_Mode_m = np.append(Storm_Mode_m, np.expand_dims(Storm_Mode_single_m, axis=0), axis=0)\n",
    "            Storm_Mode_s = np.append(Storm_Mode_s, np.expand_dims(Storm_Mode_single_s, axis=0), axis=0)\n",
    "            \n",
    "    ## Add Storm Mode to dBZ dataset:\n",
    "    ds_wrf_dbz['Storm_Mode_mod'] = (['Time', 'south_north', 'west_east'], Storm_Mode_m)\n",
    "    ds_wrf_dbz['Storm_Mode_str'] = (['Time', 'south_north', 'west_east'], Storm_Mode_s)\n",
    "    \n",
    "    ds_wrf_dbz.close()\n",
    "    \n",
    "    nc_wrf_Z.close()\n",
    "    \n",
    "    return ds_wrf_dbz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc087e98-3db1-4f8e-9ee7-994dfc6c2e7e",
   "metadata": {},
   "source": [
    "### Main Program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72815f7e-3b87-4c09-91d1-34614c269e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: 20110427: 0 |  1 |  2 |  3 |  4 |  5 |  6 |  7 |  RUNTIME：173.260705 SEC\n",
      "RUNTIME：2.887678 MIN\n",
      "RUNTIME：0.048128 HOUR\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "## WRF Model Simulation Category:\n",
    "wrf_sim_type = 'CTRL3D'\n",
    "# wrf_sim_type = 'PGW3D'\n",
    "\n",
    "## Loop through a period:\n",
    "target_date_range = pd.date_range(start='2011-4-27', end='2011-4-27', tz=pytz.utc)\n",
    "\n",
    "for dayi in target_date_range:\n",
    "        \n",
    "    ## Derive Storm Modes into dBZ dataset:\n",
    "    ds_wrf_dbz = main_function(dayi)\n",
    "    \n",
    "    ## Add attributes to Storm Mode:\n",
    "    ds_wrf_dbz.Storm_Mode_mod.attrs['long_name'] = 'Storm Mode (moderate thresholds)'\n",
    "    ds_wrf_dbz.Storm_Mode_mod.attrs['description'] = 'Classified Storm Modes with moderate thresholds (1:DCC; 2:OCC; 3:WCC; 4:DWCC; 5:BSR)'\n",
    "    \n",
    "    ds_wrf_dbz.Storm_Mode_str.attrs['long_name'] = 'Storm Mode (strong thresholds)'\n",
    "    ds_wrf_dbz.Storm_Mode_str.attrs['description'] = 'Classified Storm Modes with strong thresholds (1:DCC; 2:OCC; 3:WCC; 4:DWCC; 5:BSR)'\n",
    "    \n",
    "    ## Set output file path and name (to the original dBZ dataset):\n",
    "    file_name_dict = set_input_names(dayi)\n",
    "    file_path_name = file_name_dict['dbz']\n",
    "    \n",
    "    ds_wrf_dbz.to_netcdf(file_path_name, 'a')\n",
    "    ds_wrf_dbz.close()\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(\"RUNTIME：%f SEC\" % (end - start))\n",
    "print(\"RUNTIME：%f MIN\" % ((end - start)/60))\n",
    "print(\"RUNTIME：%f HOUR\" % ((end - start)/3600))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "689c4e20-46d1-4459-8d88-b906999deee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02242753-fdbe-4aee-8118-749c04a9f8c7",
   "metadata": {},
   "source": [
    "<font color='teal'>**Supplement Codes:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ba02c71f-4503-4196-a9f5-f592599ea4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds_type = ['moderate', 'strong']\n",
    "# print(thresholds_type[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6a759-0110-42ec-b4c1-0f5ed0cd73e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL-3.7.9",
   "language": "python",
   "name": "npl-3.7.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
